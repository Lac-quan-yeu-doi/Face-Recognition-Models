{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12c87d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phatvo/miniconda3/envs/daika/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/home/phatvo/miniconda3/envs/daika/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CASIAwebface dataset |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâœ—ï¸Ž (!) 439500/7400 [5939%] in 0.8s (518657.12/s) \n",
      "Using:  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import ConcatDataset\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Import your custom utilities\n",
    "from utils.dataset import LFWPairDataset, CASIAwebfaceDataset\n",
    "from utils.config import DATASET_PATH\n",
    "from utils.model_utils import tune_threshold, evaluate_lfw_10fold\n",
    "from utils.criterion import SphereFaceNet, CosFaceNet, ArcFaceNet, CurricularFaceNet\n",
    "\n",
    "# --- Define transforms ---\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "train_dataset = CASIAwebfaceDataset(\n",
    "    root_dir=f'{DATASET_PATH}/CASIA-WebFace',\n",
    "    split='train',\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize((112, 112)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    ")\n",
    "num_classes = train_dataset.num_of_identities\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using: \", device)\n",
    "\n",
    "dataset_path = \"/home/phatvo/callmePhineas/DACN/code/data_a_P\"\n",
    "\n",
    "# --- Dataset paths ---\n",
    "aligned_lfw_path = f'{dataset_path}/LFW'\n",
    "match_train_file = f'{dataset_path}/LFW/matchpairsDevTrain.csv'\n",
    "mismatch_train_file = f'{dataset_path}/LFW/mismatchpairsDevTrain.csv'\n",
    "match_test_file = f'{dataset_path}/LFW/matchpairsDevTest.csv'\n",
    "mismatch_test_file = f'{dataset_path}/LFW/mismatchpairsDevTest.csv'\n",
    "pairs_all_file = f'{dataset_path}/LFW/pairs.csv'\n",
    "\n",
    "# --- Combine DevTrain + DevTest for threshold tuning ---\n",
    "train_pairs_dataset_match = LFWPairDataset(\n",
    "    root_dir=aligned_lfw_path,\n",
    "    pairs_files=match_train_file,\n",
    "    transform=test_transform\n",
    ")\n",
    "train_pairs_dataset_mismatch = LFWPairDataset(\n",
    "    root_dir=aligned_lfw_path,\n",
    "    pairs_files=mismatch_train_file,\n",
    "    transform=test_transform\n",
    ")\n",
    "test_pairs_dataset_match = LFWPairDataset(\n",
    "    root_dir=aligned_lfw_path,\n",
    "    pairs_files=match_test_file,\n",
    "    transform=test_transform\n",
    ")\n",
    "test_pairs_dataset_mismatch = LFWPairDataset(\n",
    "    root_dir=aligned_lfw_path,\n",
    "    pairs_files=mismatch_test_file,\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "# Combine all pairs for threshold tuning\n",
    "combined_pairs_dataset = ConcatDataset([\n",
    "    train_pairs_dataset_match,\n",
    "    train_pairs_dataset_mismatch,\n",
    "    \n",
    "    test_pairs_dataset_match,\n",
    "    test_pairs_dataset_mismatch\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647e9018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_and_validate(\n",
    "    model,\n",
    "    batch_size=64,\n",
    "):\n",
    "    from contextlib import redirect_stdout\n",
    "    \n",
    "    log_file = \"./validation_log\"\n",
    "    with open(log_file, 'a') as f:\n",
    "        with redirect_stdout(f):\n",
    "            # --- Tune threshold ---\n",
    "            print(\"ðŸ”§ Tuning threshold on combined DevTrain + DevTest ...\")\n",
    "            # best_threshold, best_accuracy, threshold_list, accuracy_list = tune_threshold(\n",
    "            #     model, combined_pairs_dataset, batch_size, device, thresholds=np.arange(0.0, 0.5, 0.5)\n",
    "            # )\n",
    "            best_threshold, best_accuracy, _ = tune_threshold(\n",
    "                model, combined_pairs_dataset, batch_size, device, thresholds=np.arange(-0.2, 0.5, 0.02)\n",
    "            )\n",
    "            print(f\"âœ… Best threshold: {best_threshold:.4f}, Combined accuracy: {best_accuracy:.2f}%\")\n",
    "\n",
    "            # --- Validate with 10-Fold LFW ---\n",
    "            print(\"ðŸ“Š Running 10-Fold cross-validation ...\")\n",
    "            mean_acc, std_acc = evaluate_lfw_10fold(\n",
    "                model=model,\n",
    "                pairs_file=pairs_all_file,\n",
    "                batch_size=batch_size,\n",
    "                root_dir=aligned_lfw_path,\n",
    "                transform=test_transform,\n",
    "                device=device,\n",
    "                threshold=best_threshold\n",
    "            )\n",
    "\n",
    "            print(f\"ðŸŽ¯ LFW 10-Fold Accuracy: {mean_acc:.2f}% Â± {std_acc:.2f}% (Threshold: {best_threshold:.4f})\\n\\n\\n\")\n",
    "            return best_threshold, best_accuracy, mean_acc, std_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161a631c",
   "metadata": {},
   "source": [
    "# SphereFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a38fde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Load model ---\n",
    "# model_weights_path = \"./models_evaluation/CosFace_min_loss.pth\"\n",
    "# print(f\"ðŸ”¹ Loading SphereFace model from {model_weights_path}\")\n",
    "# model = SphereFaceNet(num_classes=num_classes).to(device)\n",
    "# state_dict = torch.load(model_weights_path, map_location=device)\n",
    "# model.load_state_dict(state_dict)\n",
    "# model.eval()\n",
    "\n",
    "# tune_and_validate(model=model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4863a12",
   "metadata": {},
   "source": [
    "# CosFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9a806c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Loading CosFace model from ./models_evaluation/CosFace_min_loss.pth\n",
      "init CosFace â†’ s=64.00, m=0.350\n",
      "Initialize CosFace model with backbone resnet18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.2199999999999998),\n",
       " 69.8125,\n",
       " np.float64(68.63333333333334),\n",
       " np.float64(2.1457969252574776))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Load model ---\n",
    "# resnet 18\n",
    "model_weights_path = \"./models_evaluation/CosFace_min_loss.pth\"\n",
    "model_weights_path = \"/home/phatvo/callmePhineas/DACN/working/result/checkpoints/CosFace/CosFace_min_loss.pth\"\n",
    "print(f\"ðŸ”¹ Loading CosFace model from {model_weights_path}\")\n",
    "model = CosFaceNet(num_classes=num_classes, backbone=\"resnet18\").to(device)\n",
    "state_dict = torch.load(model_weights_path, map_location=device)\n",
    "model.load_state_dict(state_dict['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "tune_and_validate(model=model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f16a09f",
   "metadata": {},
   "source": [
    "# ArcFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997917e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Loading ArcFace model from /home/phatvo/callmePhineas/DACN/working/result/checkpoints/ArcFace/ArcFace_min_loss.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.0), 50.0, np.float64(50.0), np.float64(0.0))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# --- Load model ---\n",
    "# resnet18\n",
    "model_weights_path = \"./models_evaluation/ArcFace_min_loss.pth\"\n",
    "model_weights_path = \"/home/phatvo/callmePhineas/DACN/working/result/checkpoints/ArcFace/ArcFace_min_loss.pth\"\n",
    "print(f\"ðŸ”¹ Loading ArcFace model from {model_weights_path}\")\n",
    "model = ArcFaceNet(num_classes=num_classes, backbone='resnet18').to(device)\n",
    "state_dict = torch.load(model_weights_path, map_location=device)\n",
    "model.load_state_dict(state_dict['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "tune_and_validate(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a313906",
   "metadata": {},
   "source": [
    "# CurricularFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a0c0e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Loading CurricularFace model from ./models_evaluation/CurricularFace_min_loss.pth\n",
      "init CurricularFace â†’ s=64.00, m=0.500, momentum=0.010\n",
      "Initialize CurricularFace model with backbone resnet18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.27999999999999975),\n",
       " 70.34375,\n",
       " np.float64(69.08333333333334),\n",
       " np.float64(1.6042478334444161))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Load model ---\n",
    "# resnet 50\n",
    "model_weights_path = \"./models_evaluation/CurricularFace_min_loss.pth\"\n",
    "print(f\"ðŸ”¹ Loading CurricularFace model from {model_weights_path}\")\n",
    "model = CurricularFaceNet(num_classes=num_classes, backbone='resnet18').to(device)\n",
    "state_dict = torch.load(model_weights_path, map_location=device)\n",
    "model.load_state_dict(state_dict['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "tune_and_validate(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25c2413a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CASIAwebface dataset |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâœ—ï¸Ž (!) 439500/7400 [5939%] in 0.8s (536778.44/s) \n",
      "7400\n"
     ]
    }
   ],
   "source": [
    "# ver 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from contextlib import redirect_stdout\n",
    "from utils.dataset import CASIAwebfaceDataset\n",
    "from utils.utils import Tee\n",
    "from utils.criterion import ArcFaceNet\n",
    "from utils.config import DATASET_PATH, WORKING_PATH\n",
    "from utils.model_utils import main_pipeline\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Load dataset to get number of classes\n",
    "    train_dataset = CASIAwebfaceDataset(\n",
    "        root_dir=f'{DATASET_PATH}/CASIA-WebFace',\n",
    "        transform=transforms.Compose([\n",
    "            transforms.Resize((112, 112)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    )\n",
    "    \n",
    "    print(train_dataset.num_of_identities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daika",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
