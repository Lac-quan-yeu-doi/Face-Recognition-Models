{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24292c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def foo(path):\n",
    "    count = 0\n",
    "    for fol in os.listdir(path):\n",
    "        if os.path.isfile(os.path.join(path, fol)):\n",
    "            continue\n",
    "        count += len(os.listdir(os.path.join(path, fol)))\n",
    "    return count\n",
    "\n",
    "print(foo(\"dataset/Labeled Faces in the Wild (LFW)/lfw_funneled\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a59c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_names(folder_path):\n",
    "    names = []\n",
    "    for fol in os.listdir(folder_path):\n",
    "        fol = os.path.join(folder_path, fol)\n",
    "        if os.path.isfile(fol):\n",
    "            continue\n",
    "        for file in os.listdir(fol):\n",
    "            names.append(os.path.basename(file))\n",
    "    return names\n",
    "names = get_all_names(\"dataset/Labeled Faces in the Wild (LFW)/lfw_funneled\")\n",
    "print(len(names), names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4949435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_not_used(folder_path, pair_path_list, used_image_list):\n",
    "    not_used = []\n",
    "    for pair_file in pair_path_list:\n",
    "        with open(os.path.join(folder_path, pair_file), \"r\") as f:\n",
    "            for line in f:\n",
    "                line.strip()\n",
    "                if not line:  # blank line\n",
    "                    continue \n",
    "                filename = os.path.basename(line)\n",
    "                if filename not in used_image_list:\n",
    "                    not_used.append(filename)\n",
    "    return list(set(not_used))\n",
    "\n",
    "pair_path_list = ['pairs_01.txt', 'pairs_02.txt', 'pairs_03.txt', 'pairs_04.txt', 'pairs_05.txt', 'pairs_06.txt', 'pairs_07.txt', 'pairs_08.txt', 'pairs_09.txt', 'pairs_10.txt']\n",
    "not_used = get_not_used(\"dataset/Labeled Faces in the Wild (LFW)/lfw_funneled\", pair_path_list, names)\n",
    "print(len(not_used), not_used)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573402ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([f\"pairs_{str(x).zfill(2)}.txt\" for x in range(1,11)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba9f9f3",
   "metadata": {},
   "source": [
    "## Check all image exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e8b27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "flag = True\n",
    "for file in pair_path_list:\n",
    "    file_path = os.path.join(\"dataset/Labeled Faces in the Wild (LFW)/lfw_funneled\", file)\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            img_path = os.path.join(\"dataset/Labeled Faces in the Wild (LFW)/lfw_funneled\", line)\n",
    "            if not os.path.exists(img_path):\n",
    "                flag = False\n",
    "                print(f\"Missing file: {img_path}\")\n",
    "                break\n",
    "    if not flag:\n",
    "        break\n",
    "\n",
    "print(flag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d9bf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_file = \"dataset/Labeled Faces in the Wild (LFW)/lfw_funneled/pairs_01.txt\"\n",
    "with open(pair_file, \"r\") as f:\n",
    "    lines = [line.strip() for line in f if line.strip()]  # remove blanks\n",
    "\n",
    "for i in range(0, len(lines), 4):\n",
    "    print(f\"block {i}\")\n",
    "    print(lines[i])\n",
    "    print(lines[i+3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07dd647",
   "metadata": {},
   "source": [
    "## Get unique sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da7c3a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 490623\n",
      "Found 1 unique image sizes:\n",
      "(112, 112)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def get_unique_image_sizes(root_dir):\n",
    "    unique_sizes = set()\n",
    "    img_root = os.path.join(root_dir, \"casia-webface\")\n",
    "    images_count = 0\n",
    "    for person in os.listdir(img_root):\n",
    "        person_dir = os.path.join(img_root, person)\n",
    "        if not os.path.isdir(person_dir):\n",
    "            continue\n",
    "\n",
    "        for img_name in os.listdir(person_dir):\n",
    "            images_count += 1\n",
    "            img_path = os.path.join(person_dir, img_name)\n",
    "            try:\n",
    "                with Image.open(img_path) as img:\n",
    "                    unique_sizes.add(img.size)  # (width, height)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {img_path}: {e}\")\n",
    "    print(f\"Total images: {images_count}\")\n",
    "    return unique_sizes\n",
    "\n",
    "# Example usage\n",
    "root = \"dataset/CASIA-webface\"\n",
    "sizes = get_unique_image_sizes(root)\n",
    "\n",
    "print(f\"Found {len(sizes)} unique image sizes:\")\n",
    "for s in sorted(sizes):\n",
    "    print(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701aa47d",
   "metadata": {},
   "source": [
    "## Counting lines in LWF pairs files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d75cd9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines with 3 fields: 500\n",
      "Lines with 4 fields: 500\n"
     ]
    }
   ],
   "source": [
    "file_path = \"dataset/Labeled Faces in the Wild (LFW)/pairsDevTest.txt\"  # replace with your actual file path\n",
    "\n",
    "count_3 = 0\n",
    "count_4 = 0\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split()\n",
    "        if not parts:  # skip empty lines\n",
    "            continue\n",
    "        if len(parts) == 3:\n",
    "            count_3 += 1\n",
    "        elif len(parts) == 4:\n",
    "            count_4 += 1\n",
    "\n",
    "print(f\"Lines with 3 fields: {count_3}\")\n",
    "print(f\"Lines with 4 fields: {count_4}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ac8594",
   "metadata": {},
   "source": [
    "# Preprocess image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afbe1745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing LFW dataset...\n"
     ]
    }
   ],
   "source": [
    "from main_code.utils.preprocess import *\n",
    "\n",
    "dataset_path = \"/home/phatvo/callmePhineas/DACN/working/dataset\"\n",
    "# aligned_casia_path = f'{dataset_path}/CASIA-webface-aligned'\n",
    "# if not os.path.exists(aligned_casia_path):\n",
    "#     preprocess_dataset(f'{dataset_path}/CASIA-webface', aligned_casia_path)\n",
    "#     print(f\"Preprocessing CASIA-webface dataset...\")\n",
    "\n",
    "aligned_lfw_path = f'{dataset_path}/Labeled Faces in the Wild (LFW)_aligned'\n",
    "if not os.path.exists(aligned_lfw_path):\n",
    "    preprocess_dataset(f'{dataset_path}/Labeled Faces in the Wild (LFW)', aligned_lfw_path)\n",
    "    print(f\"Preprocessing LFW dataset...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e76b7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread(\"/home/phatvo/callmePhineas/DACN/working/dataset/Labeled Faces in the Wild (LFW)_aligned/lfw_funneled/Aaron_Eckhart/Aaron_Eckhart_0001.jpg\")\n",
    "h, w = image.shape[:2]\n",
    "print(h, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656038c1",
   "metadata": {},
   "source": [
    "# Print folder tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "719f6827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Folder tree for: /home/phatvo/callmePhineas/DACN/working/dataset/face_evaluation_data/lfw (max depth=0)\n",
      "\n",
      "‚îú‚îÄ‚îÄ img.list\n",
      "‚îú‚îÄ‚îÄ imgs\n",
      "‚îî‚îÄ‚îÄ pair.list\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def print_tree(root_path, max_depth=None, prefix=\"\", current_depth=0):\n",
    "    if max_depth is not None and current_depth > max_depth:\n",
    "        return\n",
    "\n",
    "    # List entries safely (skip inaccessible)\n",
    "    try:\n",
    "        entries = sorted(os.listdir(root_path))\n",
    "    except PermissionError:\n",
    "        print(prefix + \"üö´ [Permission Denied]\")\n",
    "        return\n",
    "\n",
    "    for i, entry in enumerate(entries):\n",
    "        path = os.path.join(root_path, entry)\n",
    "        connector = \"‚îî‚îÄ‚îÄ \" if i == len(entries) - 1 else \"‚îú‚îÄ‚îÄ \"\n",
    "        print(prefix + connector + entry)\n",
    "\n",
    "        if os.path.isdir(path):\n",
    "            extension = \"    \" if i == len(entries) - 1 else \"‚îÇ   \"\n",
    "            print_tree(path, max_depth, prefix + extension, current_depth + 1)\n",
    "\n",
    "\n",
    "# === Example usage ===\n",
    "folder = \"/home/phatvo/callmePhineas/DACN/code/data_a_P\"         # or any folder path\n",
    "folder = \"/home/phatvo/callmePhineas/DACN/working/dataset/face_evaluation_data/lfw\"\n",
    "depth = 0            # set None for unlimited depth\n",
    "\n",
    "print(f\"üìÅ Folder tree for: {os.path.abspath(folder)} (max depth={depth})\\n\")\n",
    "print_tree(folder, max_depth=depth)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e3fefa",
   "metadata": {},
   "source": [
    "# Print model keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44f35ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in checkpoint:\n",
      "- epoch\n",
      "- train_loss\n",
      "- model_state_dict\n",
      "- optimizer_state_dict\n",
      "- scheduler_state_dict\n",
      "- scaler_state_dict\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Path to your .pth file\n",
    "pth_path = \"/home/phatvo/callmePhineas/DACN/code/main_code/models_evaluation/CurricularFace_min_loss.pth\"\n",
    "\n",
    "# Load checkpoint (map to CPU to avoid GPU issues)\n",
    "checkpoint = torch.load(pth_path, map_location=\"cpu\")\n",
    "\n",
    "# List all keys in the checkpoint\n",
    "print(\"Keys in checkpoint:\")\n",
    "for key in checkpoint.keys():\n",
    "    print(\"-\", key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854ece08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4795780d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322107b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daika",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
